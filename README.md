<p align="center">
  <img src="shipit.png" width="240" alt="ShipIt logo">
</p>

# ShipIt ğŸš€

[![Version](https://img.shields.io/badge/version-0.2.1-blue.svg)](https://github.com/NJLaPrell/ShipIt/releases/tag/v0.2.1)
[![Test Status](https://img.shields.io/badge/tests-97.6%25%20passing-green.svg)](./tests/ISSUES.md)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

> **Stop optimizing for humans. Start optimizing for AI.**

An AI-native Software Development Life Cycle that replaces meetings, docs, and handoffs with executable truth and state-anchored workflows.

**Status:** âœ… **Production Ready** - Fully validated with 97.6% test pass rate (82/84 tests passing)

## Table of Contents

- [The Problem](#the-problem)
- [The Solution](#the-solution)
- [Quick Start](#quick-start-30-seconds)
- [Workflow Diagram](#workflow-diagram)
- [How It Works](#how-it-works)
  - [The Workflow](#the-workflow)
  - [The Agents](#the-agents)
- [Commands](#commands)
- [Example: Ship a Feature](#example-ship-a-feature)
- [Project Structure](#project-structure)
- [Key Concepts](#key-concepts)
  - [Intent Ledger](#intent-ledger)
  - [Truth Hierarchy](#truth-hierarchy)
  - [Tests First](#tests-first-critical)
  - [High-Risk Gates](#high-risk-gates)
- [Installation](#installation)
- [Prerequisites](#prerequisites)
- [Documentation](#documentation)
- [Validation & Testing](#validation--testing)
- [FAQ](#faq)
- [Version History](#version-history)
- [License](#license)

## The Problem

Traditional SDLC assumes humans are the bottleneck. But AI agents don't need:

- âŒ Status meetings â†’ They need **state files**
- âŒ Documentation â†’ They need **executable tests**
- âŒ Handoffs â†’ They need **explicit gates**
- âŒ Institutional memory â†’ They need **do-not-repeat ledgers**

**The insight:** Most failures aren't coding errorsâ€”they're unstated assumptions, ambiguous truth sources, and forgotten constraints.

## The Solution

A framework that optimizes for _epistemology_, not coordination:

- ğŸ¯ **Executable Truth** - Tests and invariants replace documentation
- ğŸ“ **State-Anchored** - Workflow state in files, not meetings
- ğŸ” **Adversarial Verification** - Multiple agents try to break things
- ğŸ“‹ **Intent Ledger** - Planned work in `/intent/{features,bugs,tech-debt}` (not tickets)
- ğŸšª **Automated Gates** - CI/CD enforces quality
- ğŸ“Š **Drift Detection** - Entropy monitoring prevents decay
- âœ… **Auto-Validation** - Proactive validation and auto-fix for common issues
- ğŸ”„ **Smart Chaining** - Scripts automatically run dependent generators
- ğŸ“ˆ **Progress Tracking** - Clear indicators during long-running operations
- ğŸ’¡ **Context-Aware** - Intelligent next-step suggestions based on project state

## Quick Start (30 seconds)

```bash
# 1. Initialize a project
/init-project "My Awesome App"
# â†’ Creates ./projects/my-awesome-app
# â†’ Includes framework commands/rules and core scripts
# Prompts:
# 1) Tech stack [1=TS/Node, 2=Python, 3=Other]
# 2) Project description (short)
# 3) High-risk domains (comma-separated or 'none')

# 2. Scope it (optional but smart)
/scope-project "Build a todo app with auth"
# â†’ Shows all questions at once with defaults (batched prompts)
# â†’ Review answers, confirm, and select features to generate as intents
# â†’ Auto-runs: /generate-release-plan and /generate-roadmap
# â†’ Shows verification summary and next-step suggestions

# 3. Ship a feature
/ship F-001
```

That's it. The framework handles the rest through 5 automated phases with progress indicators.

## Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ShipIt Workflow                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SETUP PHASE
    â”‚
    â”œâ”€ /init-project "Project Name"
    â”‚   â””â”€ Creates project structure, copies framework files
    â”‚
    â”œâ”€ /scope-project "Description"
    â”‚   â””â”€ AI-assisted feature breakdown â†’ generates intents
    â”‚   â””â”€ Auto-runs: /generate-release-plan, /generate-roadmap
    â”‚   â””â”€ Shows verification summary and next-step suggestions
    â”‚
    â””â”€ /status
        â””â”€ Unified dashboard: intents, workflow phase, test results

PLANNING PHASE
    â”‚
    â”œâ”€ /new_intent
    â”‚   â””â”€ Creates intent file in subfolders (F-001.md, B-002.md, etc.)
    â”‚
    â”œâ”€ /generate-release-plan
    â”‚   â””â”€ Orders intents by dependencies, priorities, release targets
    â”‚   â””â”€ Validates dependencies, shows warnings
    â”‚   â””â”€ Suggests next steps
    â”‚
    â”œâ”€ /generate-roadmap
    â”‚   â””â”€ Categorizes intents: now/next/later
    â”‚   â””â”€ Suggests next steps
    â”‚
    â””â”€ /fix
        â””â”€ Auto-fixes: dependency ordering, whitespace issues
        â””â”€ Shows preview before applying fixes

EXECUTION PHASE
    â”‚
    â”œâ”€ /ship <intent-id>
    â”‚   â”‚
    â”‚   â”œâ”€ [Phase 1/5] Analysis... â³
    â”‚   â”‚   â””â”€ PM agent: Requirements clarity, confidence scoring
    â”‚   â”‚
    â”‚   â”œâ”€ [Phase 2/5] Planning... â³
    â”‚   â”‚   â””â”€ Architect: System design, CANON compliance
    â”‚   â”‚   â””â”€ âš ï¸ Human approval gate for high-risk domains
    â”‚   â”‚
    â”‚   â”œâ”€ [Phase 3/5] Implementation... â³
    â”‚   â”‚   â””â”€ QA: Writes tests first (they fail initially)
    â”‚   â”‚   â””â”€ Implementer: Writes code (tests pass)
    â”‚   â”‚
    â”‚   â”œâ”€ [Phase 4/5] Verification... â³
    â”‚   â”‚   â””â”€ QA: Adversarial testing
    â”‚   â”‚   â””â”€ Security: Threat modeling, audit
    â”‚   â”‚
    â”‚   â””â”€ [Phase 5/5] Release... â³
    â”‚       â””â”€ Docs: Updates README/CHANGELOG
    â”‚       â””â”€ Steward: Final approval
    â”‚
    â”œâ”€ /verify <intent-id>
    â”‚   â””â”€ Re-run verification phase only
    â”‚
    â””â”€ /status
        â””â”€ Check current phase, test results, recent changes

MAINTENANCE PHASE
    â”‚
    â”œâ”€ /drift_check
    â”‚   â””â”€ Calculates: PR size, test-to-code ratio, dependency growth
    â”‚
    â”œâ”€ /deploy [environment]
    â”‚   â””â”€ Runs readiness checks (tests, lint, typecheck, audit, docs)
    â”‚   â””â”€ Deploys to platform (Vercel, Netlify, Docker, AWS CDK, Manual)
    â”‚
    â””â”€ /kill <intent-id>
        â””â”€ Permanently stops work with rationale

UTILITY COMMANDS
    â”‚
    â”œâ”€ /help
    â”‚   â””â”€ Lists all commands with descriptions
    â”‚
    â”œâ”€ /suggest
    â”‚   â””â”€ Suggests next intent to work on
    â”‚
    â””â”€ /test_shipit
        â””â”€ Runs end-to-end test suite
```

## How It Works

### The Workflow

```
Intent â†’ Analysis â†’ Planning â†’ Tests â†’ Code â†’ Verify â†’ Release
```

### Security Audit Allowlist

Security checks use `scripts/audit-check.sh` with a default threshold of moderate.
If you need to temporarily accept a known advisory, add it to `security/audit-allowlist.json`
with a reason and an expiry date.

### Confidence Calibration

The `artifacts/confidence-calibration.json` file tracks confidence scores vs actual outcomes to improve calibration over time.

**Schema:**

```json
{
  "decisions": [
    {
      "id": "D-001",
      "stated_confidence": 0.85,
      "actual_outcome": "success",
      "notes": "Shipped without issues"
    }
  ]
}
```

**Fields:**

- `id`: Unique decision identifier (e.g., "D-001")
- `stated_confidence`: Confidence score (0.0-1.0) stated during analysis
- `actual_outcome`: "success" or "failure"
- `notes`: Optional notes about the outcome

Entries are automatically appended during `/verify` when outcomes are determined.

1. **You define what** (intent file)
2. **PM clarifies requirements** (executable acceptance criteria)
3. **Architect designs approach** (plan with approval gate)
4. **QA writes tests first** (they fail initially - that's good!)
5. **Implementer writes code** (makes tests pass)
6. **QA + Security verify** (adversarial validation)
7. **Docs + Steward approve** (documentation + final check)

**Progress Tracking:** Each phase shows `[Phase X/5] PhaseName... â³` while running and `âœ“` when complete, so you always know what's happening.

### The Agents

7 specialized AI agents, each with a clear role:

| Role            | Job                                | Can't Do                         |
| --------------- | ---------------------------------- | -------------------------------- |
| **Steward**     | Executive brain, veto power        | Write code                       |
| **PM**          | Intent clarity, confidence scoring | Change architecture              |
| **Architect**   | System design, CANON compliance    | Write production code            |
| **Implementer** | Code execution                     | Change architecture, write tests |
| **QA**          | Break things (adversarial)         | Weaken acceptance criteria       |
| **Security**    | Threat modeling, red team          | Waive findings                   |
| **Docs**        | Keep docs current                  | Change code behavior             |

## Commands

### Setup & Planning

| Command                  | What It Does                                                | When to Use                        |
| ------------------------ | ----------------------------------------------------------- | ---------------------------------- |
| `/init-project [name]`   | Create a new project with full structure                    | Start of new project               |
| `/scope-project [desc]`  | AI-assisted feature breakdown with batched prompts          | After init, to break down features |
| `/new_intent`            | Create a feature/bug/tech-debt intent                       | When planning new work             |
| `/generate-release-plan` | Build release plan from intents (auto-validates)            | After creating/updating intents    |
| `/generate-roadmap`      | Generate roadmap (now/next/later)                           | After creating/updating intents    |
| `/fix`                   | Auto-fix intent issues (dependency ordering, whitespace)    | When validation shows issues       |
| `/status`                | Unified dashboard: intents, workflow, tests, recent changes | Anytime to check project state     |
| `/pr <id>`               | Generate PR summary/checklist                               | Before opening a PR                |
| `/risk <id>`             | Force security/threat skim                                  | Before release or high-risk change |
| `/revert-plan <id>`      | Write rollback plan                                         | Before implementation or release   |

### Execution

| Command        | What It Does                                               | When to Use                       |
| -------------- | ---------------------------------------------------------- | --------------------------------- |
| `/ship <id>`   | Run full SDLC workflow (5 phases with progress indicators) | To implement an intent            |
| `/verify <id>` | Re-run verification phase only                             | After code changes                |
| `/kill <id>`   | Kill an intent (with rationale)                            | When work should stop permanently |

### Maintenance

| Command         | What It Does                                        | When to Use                    |
| --------------- | --------------------------------------------------- | ------------------------------ |
| `/drift_check`  | Check for entropy/decay (PR size, test ratio, deps) | Periodically to monitor health |
| `/deploy [env]` | Deploy with readiness checks                        | When ready to release          |
| `/test_shipit`  | Run end-to-end test suite                           | To validate framework itself   |

### Utilities

| Command    | What It Does                         | When to Use                 |
| ---------- | ------------------------------------ | --------------------------- |
| `/help`    | Lists all commands with descriptions | When you need a reminder    |
| `/suggest` | Suggests next intent to work on      | When unsure what to do next |

**Note:** All commands show context-aware next-step suggestions after completion. Scripts auto-verify outputs and run dependent generators (e.g., `/scope-project` automatically runs `/generate-release-plan` and `/generate-roadmap`).

All commands are available as Cursor slash commands. See [`.cursor/commands/`](./.cursor/commands/) for full documentation.

## Example: Ship a Feature

```bash
# Create an intent
/new_intent
# â†’ Creates intent/features/F-001.md with template

# Fill it in (type, motivation, acceptance criteria, etc.)

# Ship it!
/ship F-001

# Watch the magic happen:
# [Phase 1/5] Analysis... â³
# âœ… PM analyzes requirements
# [Phase 2/5] Planning... â³
# âœ… Architect proposes plan (needs your approval)
# [Phase 3/5] Implementation... â³
# âœ… QA writes tests (they fail - perfect!)
# âœ… Implementer writes code (tests pass!)
# [Phase 4/5] Verification... â³
# âœ… QA + Security verify
# [Phase 5/5] Release... â³
# âœ… Docs update README/CHANGELOG
# âœ… Steward approves
# âœ… Done!
#
# ğŸ’¡ Next steps: Review release notes, deploy, or start next intent
```

## Project Structure

```
.
â”œâ”€â”€ intent/              # What to build (features/bugs/tech-debt)
â”‚   â”œâ”€â”€ features/        # Feature intents (F-###.md)
â”‚   â”œâ”€â”€ bugs/            # Bug intents (B-###.md)
â”‚   â””â”€â”€ tech-debt/       # Tech-debt intents (T-###.md)
â”œâ”€â”€ workflow-state/      # Current execution state (active + phase files)
â”œâ”€â”€ artifacts/           # Generated files
â”‚   â”œâ”€â”€ SYSTEM_STATE.md  # Auto-generated summary for Steward
â”‚   â”œâ”€â”€ dependencies.md  # Generated dependency graph
â”‚   â””â”€â”€ confidence-calibration.json
â”œâ”€â”€ architecture/        # CANON.md (boundaries) + invariants.yml
â”œâ”€â”€ do-not-repeat/      # Failed approaches (don't rediscover)
â”œâ”€â”€ drift/              # Entropy monitoring
â””â”€â”€ roadmap/            # now.md, next.md, later.md
```

### Planning outputs

Generated planning artifacts and how they relate:

| Output               | Location                               | Purpose                                             | Generated by               |
| -------------------- | -------------------------------------- | --------------------------------------------------- | -------------------------- |
| **Release plan**     | `release/plan.md`                      | What ships when â€” intents ordered by release target | `generate-release-plan.sh` |
| **Roadmap**          | `roadmap/` (now.md, next.md, later.md) | Triage view â€” now / next / later                    | `generate-roadmap.sh`      |
| **Dependency graph** | `artifacts/dependencies.md`            | Graph of intent dependencies                        | `generate-roadmap.sh`      |

## Key Concepts

### Intent Ledger

All work lives in `/intent/` as markdown files under `features/`, `bugs/`, or `tech-debt`. Each intent has:

- Executable acceptance criteria (not "looks good")
- Confidence scores (requirements + domain assumptions)
- Invariants (hard constraints, dual form: human + executable)
- Kill criteria (explicit stop conditions)
- Rollback plan (required before implementation)

**Validation & Auto-Fix:** The framework proactively validates intents for common issues (dependency ordering conflicts, whitespace formatting, missing dependencies, circular dependencies). Use `/fix` to auto-fix issues with a preview before applying changes.

### Truth Hierarchy

When facts conflict, this is the order of precedence:

1. **Runtime behavior** (what actually happens)
2. **Tests** (executable assertions)
3. **Invariants** (hard constraints)
4. **Specs** (requirements)
5. **Architecture canon** (boundaries)
6. **Comments** (annotations)
7. **Human opinion** (last resort)

> **Rule:** If tests contradict comments, tests win. If runtime contradicts tests, that's a bugâ€”runtime is truth, tests are intent.

### Tests First (Critical!)

```
Spec â†’ Tests â†’ Code
```

Tests MUST exist BEFORE production code. The workflow enforces this:

1. QA writes tests (Phase 3)
2. Tests fail initially (nothing to pass yet)
3. Implementer writes code (Phase 4)
4. Tests pass âœ…

### High-Risk Gates

These domains require human approval:

- ğŸ” Authentication
- ğŸ’° Payments
- ğŸ”‘ Permissions/RBAC
- ğŸ—ï¸ Infrastructure
- ğŸ“‹ PII handling

## Installation

```bash
# Clone the repository
git clone https://github.com/NJLaPrell/ShipIt.git
cd ShipIt

# Install dependencies
pnpm install

# Validate Cursor integration
pnpm validate-cursor
```

## Prerequisites

- **Cursor IDE** (designed for Cursor's AI features)
- **Node.js 20+**
- **pnpm** (or npm/yarn)
- **Git**

## Documentation

- **[AGENTS.md](./AGENTS.md)** - Role definitions and conventions
- **[DIRECTORY_STRUCTURE.md](./DIRECTORY_STRUCTURE.md)** - Quick reference for project layout
- **[PILOT_GUIDE.md](./PILOT_GUIDE.md)** - Step-by-step guide for your first feature
- **[CHANGELOG.md](./CHANGELOG.md)** - Version history and changes
- **[architecture/CANON.md](./architecture/CANON.md)** - Architecture boundaries
- **[architecture/invariants.yml](./architecture/invariants.yml)** - Machine-verifiable constraints
- **[tests/ISSUES.md](./tests/ISSUES.md)** - Test results and validation status
- **[tests/README.md](./tests/README.md)** - Test structure (code, fixtures, logs, process docs)
- **[projects/README.md](./projects/README.md)** - Purpose of `projects/` (initialized projects)

## Validation & Testing

The framework has been fully validated end-to-end:

- âœ… **97.6% test pass rate** (82/84 tests passing)
- âœ… **9/9 features validated** (100%)
- âœ… **5/5 workflow phases** validated (100%)
- âœ… **Comprehensive test suite** covering all core functionality
- âœ… **End-to-end validation** complete

See [tests/ISSUES.md](./tests/ISSUES.md) for detailed test results and [tests/TEST_PLAN.md](./tests/TEST_PLAN.md) for the full test plan.

## FAQ

**Q: Do I need to understand all 7 agents?**  
A: Nope. Just use the commands. The agents handle their roles automatically during `/ship`.

**Q: What if I want to skip a phase?**  
A: Don't. The gates exist for a reason. If something feels wrong, use `/kill` instead.

**Q: Can I use this for existing projects?**  
A: Yes! Run `/init-project` in a subdirectory or adapt the structure.

**Q: What about deployment?**  
A: Use `/deploy` when ready. It runs readiness checks first.

**Q: How do I contribute to the framework itself?**  
A: Create an intent and `/ship` it! The framework eats its own dog food.

**Q: Is this production-ready?**  
A: Yes! Version 0.1.0 is released and fully validated. See [tests/ISSUES.md](./tests/ISSUES.md) for validation results.

**Q: How do I test the framework?**  
A: Run `/test_shipit` to execute the full end-to-end test suite.

## Version History

- **v0.2.1** (2026-02-04) - Patch release (version consistency)
- **v0.2.0** (2026-01-27) - UX Enhancements Release
  - **New Features:**
    - Intent validation and auto-fix (`/fix` command)
    - Output verification system with automatic generator chaining
    - Unified status dashboard (`/status` command)
    - Progress indicators for long-running operations
    - Batched interactive prompts (faster scoping workflow)
    - Context-aware next-step suggestions
  - **Improvements:**
    - Enhanced `/scope-project` with batched prompts
    - Enhanced `/generate-release-plan` with validation warnings
    - Enhanced `/generate-roadmap` with verification summaries
    - Enhanced `/ship` workflow with progress indicators
    - Improved error handling and edge case coverage
  - **Fixes:**
    - Fixed numeric validation in dependency ordering checks
    - Fixed temp file cleanup in fix-intents.sh
    - Fixed false positive grep matches in suggest-next.sh
    - Fixed fragile test parsing in status.sh
    - Removed extraneous documentation files
    - Updated outdated references

- **v0.1.0** (2026-01-23) - Initial release
  - Complete AI-native SDLC framework
  - Project initialization and scoping
  - Intent management and workflow orchestration
  - Release planning and roadmap generation
  - Comprehensive test suite with 97.6% pass rate

See [CHANGELOG.md](./CHANGELOG.md) for detailed version history.

## License

MIT

---

**Ready?** Start with `/init-project "My Project"` and see what happens. ğŸ‰

**New to ShipIt?** Check out [PILOT_GUIDE.md](./PILOT_GUIDE.md) for a step-by-step walkthrough.
